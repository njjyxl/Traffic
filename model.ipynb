{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "#plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "#plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 成都市主要地标和商圈\n",
    "#LANDMARKS = {\n",
    "  #  '春熙路': (0, 0),\n",
    "    #'太古里': (0.5, 0.5),\n",
    "    #'宽窄巷子': (-1, 1),\n",
    "    #'杜甫草堂': (-2, -1),\n",
    "    #'锦里': (-1.5, -1.5),\n",
    "    #'熊猫基地': (3, 2),\n",
    "    #'天府广场': (0.2, -0.2),\n",
    "    #'东郊记忆': (2.5, -1),\n",
    "    #'成都大熊猫繁育研究基地': (4, 3),\n",
    "#}\n",
    "\n",
    "# 地铁线路（简化版）\n",
    "#METRO_LINES = [\n",
    "  #  [('春熙路', '太古里'), ('太古里', '天府广场')],\n",
    "   # [('宽窄巷子', '春熙路'), ('春熙路', '东郊记忆')],\n",
    "    #[('天府广场', '锦里'), ('锦里', '杜甫草堂')],\n",
    "#]\n",
    "# Main landmarks and commercial areas in Chengdu\n",
    "LANDMARKS = {\n",
    "    'Chunxi Road': (0, 0),\n",
    "    'Taikoo Li': (0.5, 0.5),\n",
    "    'Kuanzhai Alley': (-1, 1),\n",
    "    'Du Fu Thatched Cottage': (-2, -1),\n",
    "    'Jinli': (-1.5, -1.5),\n",
    "    'Panda Base': (3, 2),\n",
    "    'Tianfu Square': (0.2, -0.2),\n",
    "    'Eastern Suburb Memory': (2.5, -1),\n",
    "    'Chengdu Research Base of Giant Panda Breeding': (4, 3),\n",
    "}\n",
    "\n",
    "# Metro lines (simplified version)\n",
    "METRO_LINES = [\n",
    "    [('Chunxi Road', 'Taikoo Li'), ('Taikoo Li', 'Tianfu Square')],\n",
    "    [('Kuanzhai Alley', 'Chunxi Road'), ('Chunxi Road', 'Eastern Suburb Memory')],\n",
    "    [('Tianfu Square', 'Jinli'), ('Jinli', 'Du Fu Thatched Cottage')],\n",
    "]\n",
    "\n",
    "\n",
    "def generate_chengdu_road_network(n_rings=5, n_radial=12, n_secondary=50):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # 添加环路和放射状道路\n",
    "    for r in range(1, n_rings + 1):\n",
    "        for i in range(n_radial):\n",
    "            angle = 2 * np.pi * i / n_radial\n",
    "            x = r * np.cos(angle)\n",
    "            y = r * np.sin(angle)\n",
    "            G.add_node((r, i), pos=(x, y))\n",
    "            if i > 0:\n",
    "                G.add_edge((r, i), (r, i-1))\n",
    "        G.add_edge((r, n_radial-1), (r, 0))\n",
    "    \n",
    "    for i in range(n_radial):\n",
    "        for r in range(1, n_rings):\n",
    "            G.add_edge((r, i), (r+1, i))\n",
    "    \n",
    "    # 添加中心点（天府广场）\n",
    "    G.add_node((0, 0), pos=(0, 0))\n",
    "    for i in range(n_radial):\n",
    "        G.add_edge((0, 0), (1, i))\n",
    "    \n",
    "    # 添加地标\n",
    "    for name, pos in LANDMARKS.items():\n",
    "        G.add_node(name, pos=pos)\n",
    "        # 连接到最近的节点\n",
    "        closest_node = min(G.nodes(), key=lambda n: np.linalg.norm(np.array(G.nodes[n]['pos']) - np.array(pos)) if 'pos' in G.nodes[n] else float('inf'))\n",
    "        G.add_edge(name, closest_node)\n",
    "    \n",
    "    # 添加地铁线路\n",
    "    for line in METRO_LINES:\n",
    "        for start, end in line:\n",
    "            if start in G.nodes() and end in G.nodes():\n",
    "                G.add_edge(start, end, is_metro=True)\n",
    "    \n",
    "    # 添加次要道路\n",
    "    for _ in range(n_secondary):\n",
    "        nodes = list(G.nodes())\n",
    "        node1, node2 = np.random.choice(nodes, 2, replace=False)\n",
    "        if not G.has_edge(node1, node2):\n",
    "            G.add_edge(node1, node2)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def generate_simulated_data(G, num_days=60):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    #weather_conditions = ['晴朗', '多云', '小雨', '大雨', '雪', '雾霾']\n",
    "    #weather_impact = {'晴朗': 0, '多云': 0.1, '小雨': 0.3, '大雨': 0.6, '雪': 0.8, '雾霾': 0.5}\n",
    "    \n",
    "    #special_events = ['无', '春节', '成都国际美食节', '成都国际车展', '音乐会', '马拉松比赛', '交通事故']\n",
    "    #event_impact = {'无': 0, '春节': 0.8, '成都国际美食节': 0.6, '成都国际车展': 0.7, '音乐会': 0.4, '马拉松比赛': 0.5, '交通事故': 0.7}\n",
    "    \n",
    "    weather_conditions = ['Sunny', 'Cloudy', 'Light Rain', 'Heavy Rain', 'Snow', 'Smog']\n",
    "    weather_impact = {'Sunny': 0, 'Cloudy': 0.1, 'Light Rain': 0.3, 'Heavy Rain': 0.6, 'Snow': 0.8, 'Smog': 0.5}\n",
    "\n",
    "    special_events = ['None', 'Spring Festival', 'Chengdu International Food Festival', 'Chengdu International Auto Show', 'Concert', 'Marathon', 'Traffic Accident']\n",
    "    event_impact = {'None': 0, 'Spring Festival': 0.8, 'Chengdu International Food Festival': 0.6, 'Chengdu International Auto Show': 0.7, 'Concert': 0.4, 'Marathon': 0.5, 'Traffic Accident': 0.7}\n",
    "\n",
    "    data = []\n",
    "    base_congestion = {edge: np.random.uniform(0.2, 0.8) for edge in G.edges()}\n",
    "    \n",
    "    for day in range(num_days):\n",
    "        is_weekend = day % 7 >= 5\n",
    "        is_holiday = day in [0, 1, 2, 3, 4, 5, 6]  # 假设前7天是春节假期\n",
    "        season = (day // 90) % 4  # 0: 春, 1: 夏, 2: 秋, 3: 冬\n",
    "        \n",
    "        daily_weather = np.random.choice(weather_conditions, p=[0.4, 0.3, 0.1, 0.05, 0.05, 0.1])\n",
    "        daily_event = np.random.choice(special_events, p=[0.7, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05])\n",
    "        \n",
    "        for hour in range(24):\n",
    "            for edge in G.edges():\n",
    "                road_capacity = np.random.randint(500, 2000)\n",
    "                base_traffic_volume = np.random.randint(100, road_capacity)\n",
    "                is_peak_time = 1 if (hour in [8, 9, 17, 18]) else 0\n",
    "                is_metro = G.edges[edge].get('is_metro', False)\n",
    "                public_transit_usage = np.random.randint(0, 200) * (1.5 if is_metro else 1)\n",
    "                population_density = np.random.randint(2000, 20000)\n",
    "                num_poi = np.random.randint(0, 20)\n",
    "                \n",
    "                time_factor = 1 + 0.2 * np.sin(2 * np.pi * hour / 24)\n",
    "                weather_factor = 1 + weather_impact[daily_weather] * np.random.uniform(0.5, 1.5)\n",
    "                event_factor = 1 + event_impact[daily_event] * np.random.uniform(0.5, 1.5)\n",
    "                weekend_factor = 1.2 if is_weekend else 1\n",
    "                holiday_factor = 1.5 if is_holiday else 1\n",
    "                season_factor = 1 + 0.1 * np.sin(2 * np.pi * season / 4)\n",
    "                \n",
    "                traffic_volume = (\n",
    "                    base_traffic_volume * \n",
    "                    time_factor * \n",
    "                    weather_factor * \n",
    "                    event_factor * \n",
    "                    weekend_factor * \n",
    "                    holiday_factor * \n",
    "                    season_factor\n",
    "                )\n",
    "                \n",
    "                congestion_level = (\n",
    "                    base_congestion[edge] +\n",
    "                    0.3 * (traffic_volume / road_capacity) +\n",
    "                    0.2 * is_peak_time +\n",
    "                    0.01 * (population_density / 10000) -\n",
    "                    0.05 * (public_transit_usage / 100) +\n",
    "                    0.02 * (num_poi / 10) +\n",
    "                    0.1 * weather_impact[daily_weather] +\n",
    "                    0.1 * event_impact[daily_event] +\n",
    "                    0.1 * (1 if is_weekend else 0) +\n",
    "                    0.2 * (1 if is_holiday else 0) +\n",
    "                    0.05 * np.sin(2 * np.pi * season / 4) +\n",
    "                    np.random.normal(0, 0.05)\n",
    "                )\n",
    "                congestion_level = max(0, min(congestion_level, 1))\n",
    "                \n",
    "                data.append([day, hour, edge, road_capacity, traffic_volume, \n",
    "                             is_peak_time, public_transit_usage, population_density, \n",
    "                             num_poi, daily_weather, daily_event, is_weekend, is_holiday,\n",
    "                             season, is_metro, congestion_level])\n",
    "    \n",
    "    columns = ['day', 'hour', 'edge', 'road_capacity', 'traffic_volume', \n",
    "               'is_peak_time', 'public_transit_usage', 'population_density', \n",
    "               'num_poi', 'weather', 'special_event', 'is_weekend', 'is_holiday',\n",
    "               'season', 'is_metro', 'congestion_level']\n",
    "    \n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "def prepare_data(df):\n",
    "    #df['weather_impact'] = df['weather'].map({'晴朗': 0, '多云': 0.1, '小雨': 0.3, '大雨': 0.6, '雪': 0.8, '雾霾': 0.5})\n",
    "    #df['event_impact'] = df['special_event'].map({'无': 0, '春节': 0.8, '成都国际美食节': 0.6, '成都国际车展': 0.7, '音乐会': 0.4, '马拉松比赛': 0.5, '交通事故': 0.7})\n",
    "    df['weather_impact'] = df['weather'].map({'Sunny': 0, 'Cloudy': 0.1, 'Light Rain': 0.3, 'Heavy Rain': 0.6, 'Snow': 0.8, 'Smog': 0.5})\n",
    "    df['event_impact'] = df['special_event'].map({'None': 0, 'Spring Festival': 0.8, 'Chengdu International Food Festival': 0.6, 'Chengdu International Auto Show': 0.7, 'Concert': 0.4, 'Marathon': 0.5, 'Traffic Accident': 0.7})\n",
    "\n",
    "    features = ['hour', 'road_capacity', 'traffic_volume', 'is_peak_time', \n",
    "                'public_transit_usage', 'population_density', 'num_poi',\n",
    "                'weather_impact', 'event_impact', 'is_weekend', 'is_holiday',\n",
    "                'season', 'is_metro']\n",
    "    X = df[features]\n",
    "    y = df['congestion_level']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    return mse, r2, predictions\n",
    "\n",
    "def visualize_results(y_test, predictions):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, predictions, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    #plt.xlabel('实际拥堵程度')\n",
    "    #plt.ylabel('预测拥堵程度')\n",
    "    #plt.title('实际vs预测拥堵程度')\n",
    "    plt.xlabel('Actual Congestion Level')\n",
    "    plt.ylabel('Predicted Congestion Level')\n",
    "    plt.title('Actual vs Predicted Congestion Level')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('actual_vs_predicted_congestion.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "def visualize_network(G, congestion_levels):\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    edges = list(G.edges())\n",
    "    edge_colors = [congestion_levels.get(e, 0) for e in edges]\n",
    "    \n",
    "    nx.draw(G, pos, ax=ax, node_size=20, node_color='skyblue', with_labels=False, \n",
    "            edge_color=edge_colors, edge_cmap=plt.cm.YlOrRd, width=2)\n",
    "    \n",
    "    # 添加地标标签\n",
    "    for node, (x, y) in pos.items():\n",
    "        if isinstance(node, str):  # 假设只有地标是字符串\n",
    "            plt.text(x, y, node, fontsize=8, ha='center', va='center')\n",
    "    \n",
    "    # 绘制地铁线路\n",
    "    for line in METRO_LINES:\n",
    "        x_coords, y_coords = zip(*[pos[station] for station in line[0]])\n",
    "        plt.plot(x_coords, y_coords, color='blue', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.YlOrRd, norm=plt.Normalize(vmin=min(edge_colors), vmax=max(edge_colors)))\n",
    "    sm.set_array([])\n",
    "    #cbar = plt.colorbar(sm, ax=ax, label='拥堵程度')\n",
    "    cbar = plt.colorbar(sm, ax=ax, label='Congestion Level')    \n",
    "\n",
    "    #plt.title('成都市道路网络交通流量模拟')\n",
    "    plt.title('Chengdu Road Network Traffic Flow Simulation')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('成都市道路网络交通流量模拟.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "def analyze_external_factors(df):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "    \n",
    "    df.groupby('weather')['congestion_level'].mean().plot(kind='bar', ax=axes[0, 0])\n",
    "    #axes[0, 0].set_title('不同天气条件下的平均拥堵程度')\n",
    "    #axes[0, 0].set_ylabel('平均拥堵程度')\n",
    "    axes[0, 0].set_title('Average Congestion Level by Weather Condition')\n",
    "    axes[0, 0].set_ylabel('Average Congestion Level')    \n",
    "\n",
    "    df.groupby('special_event')['congestion_level'].mean().plot(kind='bar', ax=axes[0, 1])\n",
    "    #axes[0, 1].set_title('不同特殊事件下的平均拥堵程度')\n",
    "    #axes[0, 1].set_ylabel('平均拥堵程度')\n",
    "    axes[0, 1].set_title('Average Congestion Level by Special Event')\n",
    "    axes[0, 1].set_ylabel('Average Congestion Level')\n",
    "    \n",
    "    df.groupby(['is_weekend', 'is_holiday'])['congestion_level'].mean().unstack().plot(kind='bar', ax=axes[1, 1])\n",
    "    #axes[1, 1].set_title('工作日/周末和节假日的平均拥堵程度')\n",
    "    #axes[1, 1].set_ylabel('平均拥堵程度')\n",
    "    #axes[1, 1].set_xticklabels(['工作日', '周末'])\n",
    "    #axes[1, 1].legend(['非节假日', '节假日'])\n",
    "    axes[1, 1].set_title('Average Congestion Level: Weekday_Weekend and Holiday')\n",
    "    axes[1, 1].set_ylabel('Average Congestion Level')\n",
    "    axes[1, 1].set_xticklabels(['Weekday', 'Weekend'])\n",
    "    axes[1, 1].legend(['Non-holiday', 'Holiday'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('工作日_周末和节假日的平均拥堵程度.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "def analyze_time_patterns(df):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
    "    \n",
    "    # 分析一天中的交通模式\n",
    "    df.groupby('hour')['congestion_level'].mean().plot(ax=axes[0])\n",
    "    #axes[0].set_title('一天中的平均拥堵程度变化')\n",
    "    #axes[0].set_xlabel('小时')\n",
    "    #axes[0].set_ylabel('平均拥堵程度')\n",
    "    axes[0].set_title('Average Congestion Level by Hour')\n",
    "    axes[0].set_xlabel('Hour')\n",
    "    axes[0].set_ylabel('Average Congestion Level')\n",
    "\n",
    "    # 分析一周中的交通模式\n",
    "    df['day_of_week'] = df['day'] % 7\n",
    "    #day_names = ['周一', '周二', '周三', '周四', '周五', '周六', '周日']\n",
    "    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    df.groupby('day_of_week')['congestion_level'].mean().plot(kind='bar', ax=axes[1])\n",
    "    #axes[1].set_title('一周中的平均拥堵程度变化')\n",
    "    #axes[1].set_xlabel('星期')\n",
    "    #axes[1].set_ylabel('平均拥堵程度')\n",
    "    axes[1].set_title('Average Congestion Level by Day of Week')\n",
    "    axes[1].set_xlabel('Day of Week')\n",
    "    axes[1].set_ylabel('Average Congestion Level')\n",
    "    axes[1].set_xticklabels(day_names)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('一周中的平均拥堵程度变化.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "def predict_future_traffic(model, df):\n",
    "    future_df = pd.DataFrame()\n",
    "    \n",
    "    for hour in range(24):\n",
    "        for edge in df['edge'].unique():\n",
    "            avg_data = df[(df['hour'] == hour) & (df['edge'] == edge)].select_dtypes(include=[np.number]).mean()\n",
    "            \n",
    "            # If there's no numeric data, skip this iteration\n",
    "            if avg_data.empty:\n",
    "                continue\n",
    "            \n",
    "            # Create a row for the future prediction\n",
    "            row = pd.Series({'hour': hour, 'edge': edge})\n",
    "            row = pd.concat([avg_data, row])\n",
    "            \n",
    "            # Add weather and event if they exist in the DataFrame\n",
    "            if 'weather' in df.columns:\n",
    "                most_common_weather = df[(df['hour'] == hour) & (df['edge'] == edge)]['weather'].mode().iloc[0]\n",
    "                row['weather'] = most_common_weather\n",
    "            \n",
    "            if 'event' in df.columns:\n",
    "                most_common_event = df[(df['hour'] == hour) & (df['edge'] == edge)]['event'].mode().iloc[0]\n",
    "                row['event'] = most_common_event\n",
    "            \n",
    "            # Make sure all required features are present\n",
    "            required_features = ['hour', 'congestion_level', 'speed', 'vehicle_count']\n",
    "            for feature in required_features:\n",
    "                if feature not in row.index:\n",
    "                    row[feature] = 0  # or some other default value\n",
    "            \n",
    "            # Prepare the input for the model\n",
    "            X = row[required_features].values.reshape(1, -1)\n",
    "            \n",
    "            # Predict future congestion\n",
    "            future_congestion = model.predict(X)[0]\n",
    "            \n",
    "            # Add the prediction to the row\n",
    "            row['predicted_congestion'] = future_congestion\n",
    "            \n",
    "            # Append to the future DataFrame\n",
    "            future_df = future_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return future_df\n",
    "\n",
    "def visualize_future_prediction(future_df):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for day in range(future_df['day'].min(), future_df['day'].max() + 1):\n",
    "        day_data = future_df[future_df['day'] == day]\n",
    "        plt.plot(day_data['hour'], day_data.groupby('hour')['predicted_congestion'].mean(), label=f'Day {day}')\n",
    "    \n",
    "    #plt.title('未来7天的预测拥堵程度')\n",
    "    #plt.xlabel('小时')\n",
    "    #plt.ylabel('预测拥堵程度')\n",
    "    plt.title('Predicted Congestion Level for Next 7 Days')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Predicted Congestion Level')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('未来7天的预测拥堵程度.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "def analyze_hourly_congestion(df):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    hourly_congestion = df.groupby('hour')['congestion_level'].mean()\n",
    "    hourly_congestion.plot(kind='bar')\n",
    "    #plt.title('每小时平均拥堵程度')\n",
    "    #plt.xlabel('小时')\n",
    "    #plt.ylabel('平均拥堵程度')\n",
    "    plt.title('Average Congestion Level by Hour')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Average Congestion Level')\n",
    "    for i, v in enumerate(hourly_congestion):\n",
    "        plt.text(i, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('每小时平均拥堵程度.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_weather_and_events_impact(df):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    sns.boxplot(x='weather', y='congestion_level', data=df, ax=ax1)\n",
    "    #ax1.set_title('不同天气条件对拥堵程度的影响')\n",
    "    #ax1.set_xlabel('天气')\n",
    "    #ax1.set_ylabel('拥堵程度')\n",
    "    ax1.set_title('Impact of Weather Conditions on Congestion Level')\n",
    "    ax1.set_xlabel('Weather')\n",
    "    ax1.set_ylabel('Congestion Level')\n",
    "    \n",
    "    sns.boxplot(x='special_event', y='congestion_level', data=df, ax=ax2)\n",
    "    #ax2.set_title('特殊事件对拥堵程度的影响')\n",
    "    #ax2.set_xlabel('特殊事件')\n",
    "    #ax2.set_ylabel('拥堵程度')\n",
    "    ax2.set_title('Impact of Special Events on Congestion Level')\n",
    "    ax2.set_xlabel('Special Event')\n",
    "    ax2.set_ylabel('Congestion Level')    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('天气和特殊事件对拥堵程度的影响.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def sir_congestion_model(y, t, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dSdt = -beta * S * I\n",
    "    dIdt = beta * S * I - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "def simulate_congestion_spread(G, initial_congested_nodes, beta=0.3, gamma=0.1, duration=24):\n",
    "    N = len(G.nodes())\n",
    "    I0 = len(initial_congested_nodes) / N\n",
    "    S0 = 1 - I0\n",
    "    R0 = 0\n",
    "    \n",
    "    t = np.linspace(0, duration, duration)\n",
    "    solution = odeint(sir_congestion_model, [S0, I0, R0], t, args=(beta, gamma))\n",
    "    S, I, R = solution.T\n",
    "    \n",
    "    congestion_levels = pd.DataFrame(index=G.nodes(), columns=range(duration))\n",
    "    for node in G.nodes():\n",
    "        if node in initial_congested_nodes:\n",
    "            congestion_levels.loc[node] = I\n",
    "        else:\n",
    "            congestion_levels.loc[node] = S0 - S\n",
    "    \n",
    "    return congestion_levels\n",
    "\n",
    "def predict_traffic_demand(df, poi_data, population_data, economic_data):\n",
    "    # 这里需要根据实际数据结构进行调整\n",
    "    X = pd.concat([poi_data, population_data, economic_data], axis=1)\n",
    "    y = df.groupby('edge')['traffic_volume'].mean()\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model.predict(X)\n",
    "\n",
    "def adaptive_grid_partition(G, traffic_flow, threshold=0.1):\n",
    "    def split_cell(cell):\n",
    "        x, y, w, h = cell\n",
    "        return [\n",
    "            (x, y, w/2, h/2),\n",
    "            (x+w/2, y, w/2, h/2),\n",
    "            (x, y+h/2, w/2, h/2),\n",
    "            (x+w/2, y+h/2, w/2, h/2)\n",
    "        ]\n",
    "    \n",
    "    cells = [(0, 0, 1, 1)]  # 初始单元格覆盖整个区域\n",
    "    while True:\n",
    "        new_cells = []\n",
    "        for cell in cells:\n",
    "            nodes_in_cell = [node for node in G.nodes() if cell[0] <= G.nodes[node]['pos'][0] < cell[0]+cell[2] and cell[1] <= G.nodes[node]['pos'][1] < cell[1]+cell[3]]\n",
    "            flow_variation = np.std([traffic_flow[node] for node in nodes_in_cell])\n",
    "            if flow_variation > threshold and len(nodes_in_cell) > 1:\n",
    "                new_cells.extend(split_cell(cell))\n",
    "            else:\n",
    "                new_cells.append(cell)\n",
    "        if len(new_cells) == len(cells):\n",
    "            break\n",
    "        cells = new_cells\n",
    "    \n",
    "    return cells\n",
    "\n",
    "def visualize_adaptive_grid(G, cells, traffic_flow):\n",
    "    # 创建一个图形和一个主要的 Axes 对象\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    \n",
    "    # 绘制网络\n",
    "    nx.draw(G, nx.get_node_attributes(G, 'pos'), node_size=20, node_color='lightgray', with_labels=False, ax=ax)\n",
    "    \n",
    "    # 创建一个颜色映射\n",
    "    cmap = plt.cm.get_cmap('YlOrRd')\n",
    "    norm = plt.Normalize(vmin=min(traffic_flow.values()), vmax=max(traffic_flow.values()))\n",
    "    \n",
    "    # 绘制网格并为每个单元格上色\n",
    "    for cell in cells:\n",
    "        x, y, w, h = cell\n",
    "        nodes_in_cell = [node for node in G.nodes() if x <= G.nodes[node]['pos'][0] < x+w and y <= G.nodes[node]['pos'][1] < y+h]\n",
    "        cell_flow = sum(traffic_flow[node] for node in nodes_in_cell) / len(nodes_in_cell) if nodes_in_cell else 0\n",
    "        color = cmap(norm(cell_flow))\n",
    "        ax.add_patch(plt.Rectangle((x, y), w, h, fill=True, facecolor=color, edgecolor='black', alpha=0.5))\n",
    "    \n",
    "    # 创建一个 ScalarMappable 对象用于颜色条\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    # 添加颜色条，明确指定 ax 参数\n",
    "    cbar = fig.colorbar(sm, ax=ax, label='Average Traffic Flow')\n",
    "    \n",
    "    ax.set_title('Adaptive Grid Visualization')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('adaptive_grid.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_congestion_heatmap(G, df):\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    \n",
    "    node_congestion = {}\n",
    "    for edge in G.edges():\n",
    "        avg_congestion = df[df['edge'] == edge]['congestion_level'].mean()\n",
    "        node_congestion[edge[0]] = node_congestion.get(edge[0], []) + [avg_congestion]\n",
    "        node_congestion[edge[1]] = node_congestion.get(edge[1], []) + [avg_congestion]\n",
    "    \n",
    "    for node in node_congestion:\n",
    "        node_congestion[node] = np.mean(node_congestion[node])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    \n",
    "    colors = ['green', 'yellow', 'red']\n",
    "    n_bins = 100\n",
    "    cmap = LinearSegmentedColormap.from_list('custom', colors, N=n_bins)\n",
    "    \n",
    "    congestion_values = [node_congestion.get(node, 0) for node in G.nodes()]\n",
    "    nx.draw(G, pos, node_color=congestion_values, node_size=50, cmap=cmap, with_labels=False, ax=ax)\n",
    "    \n",
    "    for node, (x, y) in pos.items():\n",
    "        if isinstance(node, str):\n",
    "            ax.text(x, y, node, fontsize=8, ha='center', va='center', bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min(congestion_values), vmax=max(congestion_values)))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax)\n",
    "    cbar.set_label('Average Congestion Level')\n",
    "    \n",
    "    ax.set_title('Chengdu Congestion Hotspot Map')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('chengdu_congestion_hotspot_map.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "def integrate_analysis(G, df, congestion_spread, predicted_demand, cells):\n",
    "\n",
    "    #  交通需求预测与小时级别拥堵分析\n",
    "    def analyze_demand_vs_hourly_congestion():\n",
    "        hourly_congestion = df.groupby(['day', 'hour', 'edge'])['congestion_level'].mean().reset_index()\n",
    "        demand_vs_congestion = pd.merge(hourly_congestion, \n",
    "                                        pd.DataFrame({'edge': G.edges(), 'predicted_demand': predicted_demand}),\n",
    "                                        on='edge')\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.scatterplot(x='predicted_demand', y='congestion_level', hue='hour', data=demand_vs_congestion)\n",
    "        plt.title('Predicted Demand vs Actual Congestion Level')\n",
    "        plt.xlabel('Predicted Demand')\n",
    "        plt.ylabel('Actual Congestion Level')\n",
    "        plt.savefig('demand_vs_congestion.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    #  自适应网格与拥堵热点分析\n",
    "    def analyze_adaptive_grid_hotspots():\n",
    "        cell_congestion = {}\n",
    "        for cell in cells:\n",
    "            x, y, w, h = cell\n",
    "            nodes_in_cell = [node for node in G.nodes() if x <= G.nodes[node]['pos'][0] < x+w and y <= G.nodes[node]['pos'][1] < y+h]\n",
    "            cell_congestion[cell] = df[df['edge'].isin(nodes_in_cell)]['congestion_level'].mean()\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        nx.draw(G, nx.get_node_attributes(G, 'pos'), node_size=20, node_color='lightgray', with_labels=False, ax=ax)\n",
    "    \n",
    "        for cell, congestion in cell_congestion.items():\n",
    "            x, y, w, h = cell\n",
    "            ax.add_patch(plt.Rectangle((x, y), w, h, fill=True, facecolor=plt.cm.YlOrRd(congestion), edgecolor='none', alpha=0.5))\n",
    "    \n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.YlOrRd, norm=plt.Normalize(vmin=min(cell_congestion.values()), vmax=max(cell_congestion.values())))\n",
    "        sm.set_array([])\n",
    "        plt.colorbar(sm, ax=ax, label='Average Congestion Level')\n",
    "    \n",
    "        ax.set_title('Congestion Hotspots with Adaptive Grid')\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('adaptive_grid_hotspots.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # 执行整合分析\n",
    "    #analyze_congestion_spread_factors()\n",
    "    analyze_demand_vs_hourly_congestion()\n",
    "    analyze_adaptive_grid_hotspots()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 生成成都市道路网络\n",
    "    G = generate_chengdu_road_network()\n",
    "    \n",
    "    # 生成模拟数据\n",
    "    df = generate_simulated_data(G)\n",
    "    \n",
    "    # 准备数据\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df)\n",
    "    \n",
    "    # 训练模型\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # 评估模型\n",
    "    mse, r2, predictions = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"均方误差: {mse}\")\n",
    "    print(f\"R2 分数: {r2}\")\n",
    "    \n",
    "    # 可视化结果\n",
    "    visualize_results(y_test, predictions)\n",
    "    \n",
    "    # 可视化道路网络\n",
    "    average_congestion = df.groupby('edge')['congestion_level'].mean().to_dict()\n",
    "    visualize_network(G, average_congestion)\n",
    "    \n",
    "    # 分析外部因素的影响\n",
    "    analyze_external_factors(df)\n",
    "    \n",
    "    # 分析时间模式\n",
    "    analyze_time_patterns(df)\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(\"\\n特征重要性:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    analyze_hourly_congestion(df)\n",
    "    analyze_weather_and_events_impact(df)\n",
    "    #analyze_traffic_light_impact(df)\n",
    "    create_congestion_heatmap(G, df)\n",
    "    \n",
    "    # 模拟拥堵传播\n",
    "    initial_congested_nodes = np.random.choice(list(G.nodes()), size=5, replace=False)\n",
    "    congestion_spread = simulate_congestion_spread(G, initial_congested_nodes)\n",
    "    \n",
    "    # 交通需求预测\n",
    "    poi_data = pd.DataFrame(np.random.rand(len(G.edges()), 5), index=G.edges(), columns=['poi1', 'poi2', 'poi3', 'poi4', 'poi5'])\n",
    "    population_data = pd.DataFrame(np.random.randint(1000, 10000, size=(len(G.edges()), 1)), index=G.edges(), columns=['population'])\n",
    "    economic_data = pd.DataFrame(np.random.randint(5000, 20000, size=(len(G.edges()), 1)), index=G.edges(), columns=['gdp'])\n",
    "    predicted_demand = predict_traffic_demand(df, poi_data, population_data, economic_data)\n",
    "    \n",
    "    # 自适应网格划分\n",
    "    traffic_flow = dict(zip(G.nodes(), np.random.rand(len(G.nodes()))))\n",
    "    cells = adaptive_grid_partition(G, traffic_flow)\n",
    "    visualize_adaptive_grid(G, cells, traffic_flow)\n",
    "    \n",
    "    # 整合分析\n",
    "    integrate_analysis(G, df, congestion_spread, predicted_demand, cells)\n",
    "    \n",
    "#     # 预测未来交通状况\n",
    "#     future_df = predict_future_traffic(model, df)\n",
    "#     visualize_future_prediction(future_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec266fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\81405\\AppData\\Local\\Temp\\ipykernel_24580\\3004389547.py\", line 134, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\81405\\AppData\\Local\\Temp\\ipykernel_24580\\3004389547.py\", line 123, in main\n",
      "    G = generate_chengdu_road_network()\n",
      "NameError: name 'generate_chengdu_road_network' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1115, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"D:\\Application\\anaconda3\\envs\\python_3.9\\lib\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "# 利用SIR模型进行拥堵应对策略\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sir_traffic_model(y, t, N, base_beta, base_gamma, hourly_congestion, peak_factor=1.5, off_peak_factor=1.0):\n",
    "    S, I, R = y\n",
    "    hour = int(t) % 24\n",
    "    current_congestion = hourly_congestion[hour]\n",
    "    \n",
    "    # 定义早高峰和晚高峰\n",
    "    morning_peak = (7 <= hour < 10)\n",
    "    evening_peak = (17 <= hour < 20)\n",
    "    \n",
    "    # 在高峰期调整beta和gamma\n",
    "    if morning_peak or evening_peak:\n",
    "        current_beta = base_beta * peak_factor * (1 + current_congestion)\n",
    "        current_gamma = base_gamma / peak_factor / (1 + current_congestion)\n",
    "    else:\n",
    "        current_beta = base_beta * off_peak_factor * (1 + current_congestion)\n",
    "        current_gamma = base_gamma / off_peak_factor / (1 + current_congestion)\n",
    "    \n",
    "    dSdt = -current_beta * S * I / N\n",
    "    dIdt = current_beta * S * I / N - current_gamma * I\n",
    "    dRdt = current_gamma * I\n",
    "    return dSdt, dIdt, dRdt\n",
    "\n",
    "def analyze_interventions(df):\n",
    "    N = 1000  # 总道路数量\n",
    "    \n",
    "    # 计算每小时的平均拥堵程度\n",
    "    hourly_congestion = df.groupby('hour')['congestion_level'].mean()\n",
    "    hourly_congestion = (hourly_congestion - hourly_congestion.min()) / (hourly_congestion.max() - hourly_congestion.min())\n",
    "    \n",
    "    # 初始条件\n",
    "    initial_congestion = hourly_congestion[0]\n",
    "    I0 = int(N * initial_congestion)\n",
    "    R0 = 0\n",
    "    S0 = N - I0 - R0\n",
    "    \n",
    "    t = np.linspace(0, 24, 145)  # 模拟一天，每10分钟一个数据点\n",
    "    \n",
    "    interventions = {\n",
    "        'No Intervention': {'beta': 0.3, 'gamma': 0.1, 'peak_factor': 1.5, 'off_peak_factor': 1.0},\n",
    "        'Traffic Signal Optimization': {'beta': 0.25, 'gamma': 0.12, 'peak_factor': 1.4, 'off_peak_factor': 1.0},\n",
    "        'Public Transport Improvement': {'beta': 0.22, 'gamma': 0.15, 'peak_factor': 1.3, 'off_peak_factor': 1.0},\n",
    "        'Road Expansion': {'beta': 0.28, 'gamma': 0.18, 'peak_factor': 1.4, 'off_peak_factor': 1.1},\n",
    "        'Congestion Pricing': {'beta': 0.24, 'gamma': 0.14, 'peak_factor': 1.2, 'off_peak_factor': 1.0},\n",
    "        'Promote Work-from-Home': {'beta': 0.20, 'gamma': 0.12, 'peak_factor': 1.3, 'off_peak_factor': 0.9},\n",
    "        'Smart Traffic Management': {'beta': 0.23, 'gamma': 0.16, 'peak_factor': 1.3, 'off_peak_factor': 1.1},\n",
    "        'Encourage Bicycle Usage': {'beta': 0.26, 'gamma': 0.13, 'peak_factor': 1.4, 'off_peak_factor': 1.0},\n",
    "        'Staggered Work Hours': {'beta': 0.27, 'gamma': 0.11, 'peak_factor': 1.3, 'off_peak_factor': 1.1},\n",
    "        'Implement BRT Lanes': {'beta': 0.21, 'gamma': 0.17, 'peak_factor': 1.2, 'off_peak_factor': 1.0},\n",
    "        'Dynamic Road Pricing': {'beta': 0.25, 'gamma': 0.15, 'peak_factor': 1.2, 'off_peak_factor': 1.0},\n",
    "        'Improve Last-Mile Connectivity': {'beta': 0.28, 'gamma': 0.14, 'peak_factor': 1.4, 'off_peak_factor': 1.1},\n",
    "        'Carpool Incentives': {'beta': 0.26, 'gamma': 0.13, 'peak_factor': 1.3, 'off_peak_factor': 1.0},\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for intervention, params in interventions.items():\n",
    "        solution = odeint(sir_traffic_model, [S0, I0, R0], t, args=(N, params['beta'], params['gamma'], hourly_congestion, params['peak_factor'], params['off_peak_factor']))\n",
    "        S, I, R = solution.T\n",
    "        plt.plot(t, I, label=intervention)\n",
    "    \n",
    "    # 绘制实际拥堵数据\n",
    "    actual_congestion = [int(N * hourly_congestion[hour % 24]) for hour in range(25)]\n",
    "    plt.plot(range(25), actual_congestion, 'k--', label='Actual Congestion')\n",
    "    \n",
    "    plt.title('Effect of Interventions on Traffic Congestion Over a Day (With Peak Hours)')\n",
    "    plt.xlabel('Time (hours)')\n",
    "    plt.ylabel('Number of Congested Roads')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(0, 25, 3))\n",
    "    plt.ylim(0, N)\n",
    "    \n",
    "    # 标记早晚高峰时段\n",
    "    plt.axvspan(7, 10, alpha=0.2, color='yellow', label='Morning Peak')\n",
    "    plt.axvspan(17, 20, alpha=0.2, color='orange', label='Evening Peak')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('intervention_effects_on_congestion_daily_with_peaks_extended.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 计算和打印平均拥堵水平\n",
    "    results = []\n",
    "    for intervention, params in interventions.items():\n",
    "        solution = odeint(sir_traffic_model, [S0, I0, R0], t, args=(N, params['beta'], params['gamma'], hourly_congestion, params['peak_factor'], params['off_peak_factor']))\n",
    "        _, I, _ = solution.T\n",
    "        avg_congestion = np.mean(I) / N * 100\n",
    "        peak_congestion = np.max(I) / N * 100\n",
    "        results.append((intervention, avg_congestion, peak_congestion))\n",
    "        print(f\"{intervention}: Average congestion = {avg_congestion:.2f}%, Peak congestion = {peak_congestion:.2f}%\")\n",
    "\n",
    "    actual_avg_congestion = np.mean(actual_congestion) / N * 100\n",
    "    actual_peak_congestion = np.max(actual_congestion) / N * 100\n",
    "    print(f\"Actual: Average congestion = {actual_avg_congestion:.2f}%, Peak congestion = {actual_peak_congestion:.2f}%\")\n",
    "\n",
    "    # 排序并打印最有效的措施\n",
    "    results.sort(key=lambda x: x[1])  # 按平均拥堵程度排序\n",
    "    print(\"\\nMost effective interventions (by average congestion):\")\n",
    "    for i, (intervention, avg_congestion, _) in enumerate(results[:5], 1):\n",
    "        print(f\"{i}. {intervention}: {avg_congestion:.2f}%\")\n",
    "\n",
    "    results.sort(key=lambda x: x[2])  # 按峰值拥堵程度排序\n",
    "    print(\"\\nMost effective interventions (by peak congestion):\")\n",
    "    for i, (intervention, _, peak_congestion) in enumerate(results[:5], 1):\n",
    "        print(f\"{i}. {intervention}: {peak_congestion:.2f}%\")\n",
    "\n",
    "    # 计算每种干预措施的平均拥堵水平\n",
    "    for intervention, params in interventions.items():\n",
    "        solution = odeint(sir_traffic_model, [S0, I0, R0], t, args=(N, params['beta'], params['gamma'], hourly_congestion))\n",
    "        _, I, _ = solution.T\n",
    "        avg_congestion = np.mean(I) / N * 100\n",
    "        print(f\"{intervention}: Average congestion level = {avg_congestion:.2f}%\")\n",
    "\n",
    "    # 计算实际拥堵的平均水平\n",
    "    actual_avg_congestion = np.mean(actual_congestion) / N * 100\n",
    "    print(f\"Actual: Average congestion level = {actual_avg_congestion:.2f}%\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    G = generate_chengdu_road_network()\n",
    "    \n",
    "    # Generate simulated data\n",
    "    df = generate_simulated_data(G)\n",
    "    \n",
    "    # Simulate congestion spread\n",
    "    initial_congested_nodes = np.random.choice(list(G.nodes()), size=5, replace=False)\n",
    "    \n",
    "    analyze_interventions(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a9f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415c5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.9",
   "language": "python",
   "name": "python_3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
